{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling DiffEqFlux [aae7a2af-3d4f-5e19-a356-7da93b79d9d0]\n",
      "└ @ Base loading.jl:1278\n",
      "┌ Info: Precompiling MLDataUtils [cc2ba9b6-d476-5e6d-8eaf-a92d5412d41d]\n",
      "└ @ Base loading.jl:1278\n",
      "┌ Info: Precompiling MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using DiffEqFlux, OrdinaryDiffEq, Flux, NNlib, MLDataUtils, Printf\n",
    "using Flux: logitcrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using MLDatasets\n",
    "using CUDA\n",
    "CUDA.allowscalar(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadmnist(batchsize = bs, train_val_split = 0.8333)\n",
    "    # Use MLDataUtils LabelEnc for natural onehot conversion\n",
    "    onehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw,\n",
    "                                      LabelEnc.NativeLabels(collect(0:9)))\n",
    "    # Load MNIST\n",
    "    imgs, labels_raw = MNIST.testdata();\n",
    "    # Process images into (H,W,C,BS) batches\n",
    "    x_data = Float32.(reshape(imgs, size(imgs,1), size(imgs,2), 1, size(imgs,3)))\n",
    "    y_data = onehot(labels_raw)\n",
    "    (x_train, y_train), (x_test, y_test) = stratifiedobs((x_data, y_data),\n",
    "                                                         p = train_split)\n",
    "    return (\n",
    "        # Use Flux's DataLoader to automatically minibatch and shuffle the data\n",
    "        DataLoader(gpu.(collect.((x_train, y_train))); batchsize = batchsize,\n",
    "                   shuffle = true),\n",
    "        # Don't shuffle the test data\n",
    "        DataLoader(gpu.(collect.((x_test, y_test))); batchsize = batchsize,\n",
    "                   shuffle = false)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "const bs = 128\n",
    "const train_split = 0.9\n",
    "train_dataloader, test_dataloader = loadmnist(bs, train_split)\n",
    "\n",
    "down = Chain(flatten, Dense(784, 20, tanh)) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn = Chain(Dense(20, 10, tanh),\n",
    "           Dense(10, 10, tanh),\n",
    "           Dense(10, 20, tanh)) |> gpu\n",
    "\n",
    "\n",
    "nn_ode = NeuralODE(nn, (0.f0, 100.f0), Tsit5(),\n",
    "                   save_everystep = false,\n",
    "                   reltol = 1e-3, abstol = 1e-3,\n",
    "                   save_start = false) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc  = Chain(Dense(20, 10)) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function DiffEqArray_to_Array(x)\n",
    "    xarr = gpu(x)\n",
    "    return reshape(xarr, size(xarr)[1:2])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build our over-all model topology\n",
    "model = Chain(down,\n",
    "              nn_ode,\n",
    "              DiffEqArray_to_Array,\n",
    "              fc) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = train_dataloader.data[1][:, :, :, 1:1], train_dataloader.data[2][:, 1:1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = down(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn(x_d);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We can see that we can compute the forward pass through the NN topology\n",
    "# featuring an NNODE layer.\n",
    "x_m = model(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   1 || Train Accuracy: 9.377 || Test Accuracy: 9.710\n",
      "Iter:  11 || Train Accuracy: 9.743 || Test Accuracy: 9.710\n",
      "Iter:  21 || Train Accuracy: 9.799 || Test Accuracy: 9.810\n",
      "Iter:  31 || Train Accuracy: 9.821 || Test Accuracy: 9.810\n",
      "Iter:  41 || Train Accuracy: 9.743 || Test Accuracy: 9.710\n",
      "Iter:  51 || Train Accuracy: 9.799 || Test Accuracy: 9.810\n",
      "Iter:  61 || Train Accuracy: 9.821 || Test Accuracy: 9.810\n",
      "Iter:  71 || Train Accuracy: 10.277 || Test Accuracy: 10.310\n"
     ]
    }
   ],
   "source": [
    "classify(x) = argmax.(eachcol(x))\n",
    "\n",
    "function accuracy(model, data; n_batches = 100)\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for (i, (x, y)) in enumerate(collect(data))\n",
    "        # Only evaluate accuracy for n_batches\n",
    "        i > n_batches && break\n",
    "        target_class = classify(cpu(y))\n",
    "        predicted_class = classify(cpu(model(x)))\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end\n",
    "\n",
    "# burn in accuracy\n",
    "accuracy(model, train_dataloader)\n",
    "\n",
    "loss(x, y) = logitcrossentropy(model(x), y)\n",
    "\n",
    "# burn in loss\n",
    "loss(img, lab)\n",
    "\n",
    "opt = ADAM(0.05)\n",
    "iter = 0\n",
    "\n",
    "cb() = begin\n",
    "    global iter += 1\n",
    "    # Monitor that the weights do infact update\n",
    "    # Every 10 training iterations show accuracy\n",
    "    if iter % 10 == 1\n",
    "        train_accuracy = accuracy(model, train_dataloader) * 100\n",
    "        test_accuracy = accuracy(model, test_dataloader;\n",
    "                                 n_batches = length(test_dataloader)) * 100\n",
    "        @printf(\"Iter: %3d || Train Accuracy: %2.3f || Test Accuracy: %2.3f\\n\",\n",
    "                iter, train_accuracy, test_accuracy)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Train the NN-ODE and monitor the loss and weights.\n",
    "Flux.train!(loss, params(down, nn_ode.p, fc), train_dataloader, opt, cb = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
