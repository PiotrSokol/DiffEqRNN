{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "julia-1.5",
   "display_name": "Julia 1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DiffEqFlux, OrdinaryDiffEq, Flux, Optim\n",
    "include(\"/Users/piotrsokol/Documents/RNNODE.jl/src/rnn_ode.jl\")\n",
    "using Zygote\n",
    "using Flux: logitcrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using MLDatasets, NNlib, MLDataUtils\n",
    "#ENV[\"PYTHON\"] = \"/Users/piotrsokol/anaconda3/envs/bortho/bin/python\"\n",
    "#using Pkg; Pkg.build(\"PyCall\")\n",
    "using PyCall\n",
    "using CUDA\n",
    "using Parameters: @with_kw, @unpack\n",
    "import Statistics: mean\n",
    "using NPZ, BSON\n",
    "using UUIDs\n",
    "using EllipsisNotation\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "@with_kw mutable struct Args\n",
    "    _seed::Int\n",
    "    alpha::Float32 = 1.5f0\n",
    "    architecture::String = \"RNN_TANH\"; @assert architecture ∈ [\"RNN_TANH\", \"GRU\", \"LSTM\"]\n",
    "    batchsize::Int = 128\n",
    "    cuda::Bool=false\n",
    "    data_dir = nothing\n",
    "    dataset::String = \"cm\"\n",
    "    factor = 1.f0\n",
    "    gradient_clipping::Float32 = 0.f0\n",
    "    hidden_size::Int = 250\n",
    "    hpsearch::Bool=false\n",
    "    initializer::String=\"default\"; @assert initializer ∈ [\"default\",\"limitcycle\"]\n",
    "    input_size::Int = 10\n",
    "    interpolation::String=\"PiecewiseConstant\"; @assert interpolation==\"PiecewiseConstant\"\n",
    "    lr::Float32 = 0.01f0\n",
    "    max_epochs::Int = dataset == \"cm\" ? 60 : 150\n",
    "    max_lag::Int=120\n",
    "    min_lag::Int=100\n",
    "    optimizer::String = \"ADAM\"; @assert optimizer ∈ [\"ADAM\",\"Momentum\"]\n",
    "    output_size::Int = 9\n",
    "    patience::Int=10\n",
    "    python_code_dir = nothing\n",
    "    save_dir = nothing\n",
    "    sequence_len = 10\n",
    "    time_interval::Int = 100\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Args\n",
       "  _seed: Int64 1\n",
       "  alpha: Float32 1.5f0\n",
       "  architecture: String \"RNN_TANH\"\n",
       "  batchsize: Int64 128\n",
       "  cuda: Bool false\n",
       "  data_dir: Nothing nothing\n",
       "  dataset: String \"rcm\"\n",
       "  factor: Float32 1.0f0\n",
       "  gradient_clipping: Float32 0.0f0\n",
       "  hidden_size: Int64 250\n",
       "  hpsearch: Bool false\n",
       "  initializer: String \"default\"\n",
       "  input_size: Int64 10\n",
       "  interpolation: String \"PiecewiseConstant\"\n",
       "  lr: Float32 0.01f0\n",
       "  max_epochs: Int64 150\n",
       "  max_lag: Int64 120\n",
       "  min_lag: Int64 100\n",
       "  optimizer: String \"ADAM\"\n",
       "  output_size: Int64 9\n",
       "  patience: Int64 10\n",
       "  python_code_dir: String \"/Users/piotrsokol/Documents/block-orthogonal/src/\"\n",
       "  save_dir: Nothing nothing\n",
       "  sequence_len: Int64 10\n",
       "  time_interval: Int64 100\n"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "args = Args(_seed=1, python_code_dir=\"/Users/piotrsokol/Documents/block-orthogonal/src/\", dataset = \"rcm\")\n",
    "@unpack batchsize, hidden_size, input_size, output_size, max_epochs, data_dir, save_dir, factor, optimizer, hpsearch, gradient_clipping, alpha, cuda, python_code_dir, patience, min_lag, max_lag, time_interval, dataset, sequence_len, architecture,initializer  = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.5f0, 0.01f0)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "optimizer = Symbol(optimizer)\n",
    "α, η = args.alpha, args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Float32"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "FT = Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "onehot (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "function onehot(labels_raw; ntoken::Int=8)\n",
    "    return  convertlabel(LabelEnc.OneOfK, labels_raw, LabelEnc.NativeLabels(collect(0:ntoken)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cpu (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "if cuda\n",
    "    try \n",
    "        using CUDA\n",
    "        device = has_cuda ? gpu : cpu\n",
    "    catch ex\n",
    "        @warn \"CUDA requested but CUDA.jl fails to load\" exception=(ex,catch_backtrace())\n",
    "        device = cpu\n",
    "    end\n",
    "else\n",
    "    device = cpu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3-element Array{Symbol,1}:\n",
       " :train\n",
       " :valid\n",
       " :test"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sets = hpsearch ? [:train, :valid] : [:train, :valid,:test]  # if doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "import sys\n",
    "sys.path.insert(0, $python_code_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "get_data (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "function get_data(batchsize, dataset, device; max_lag, min_lag, set::Symbol, time_interval)\n",
    "    \n",
    "    N = Dict(:train=> Int(1e4), :test=> Int(1e3), :valid=>Int(1e4))\n",
    "    if dataset == \"rcm\"\n",
    "        x,y = pyimport(\"data_utils\")[\"_generate_random_copy_memory\"](min_lag,max_lag,N[set] ,set)\n",
    "    elseif dataset == \"cm\"\n",
    "        x,y = pyimport(\"data_utils\")[\"_generate_copy_memory\"](time_interval, N[set], set)\n",
    "    end\n",
    "    \n",
    "    println(size(x))\n",
    "    x = permutedims(x)\n",
    "    y = reshape(y, size(y)[1],size(y)[2],1)\n",
    "    y = mapslices( x-> onehot(vec(x)), y, dims=[1,3])\n",
    "\n",
    "    return DataLoader(device.((x, y)); batchsize = batchsize, shuffle = set == :train ? true : false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10000, 140)\n",
      "(10000, 140)\n",
      "(1000, 140)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"a7635d5a-2e81-11eb-1f61-014396c9a361.bson\""
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "_get_data(set) = get_data(batchsize, \"rcm\", device, max_lag=max_lag, min_lag=min_lag, set=set, time_interval=time_interval)\n",
    "if hpsearch\n",
    "    train_loader,valid_loader = _get_data.(sets)\n",
    "    eval_sets = Dict(:valid=>valid_loader)\n",
    "else\n",
    "    train_loader,valid_loader, test_loader = _get_data.(sets)\n",
    "    eval_sets = Dict(:valid=>valid_loader, :test=>test_loader)\n",
    "    fname = string(uuid1(),\".bson\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dict{Symbol,Dict{Symbol,Array{Float32,1}}} with 3 entries:\n",
       "  :test  => Dict{Symbol,Array{Float32,1}}(:loss=>[],:accuracy=>[])\n",
       "  :train => Dict{Symbol,Array{Float32,1}}(:loss=>[],:accuracy=>[])\n",
       "  :valid => Dict{Symbol,Array{Float32,1}}(:loss=>[],:accuracy=>[])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "metrics = Dict(:train=> Dict(:loss=>FT[], :accuracy=>FT[]), :test=>Dict(:loss=>FT[], :accuracy=>FT[]), :valid=>Dict(:loss=>FT[], :accuracy=>FT[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsteps =  dataset == \"rcm\" ? collect(FT, 1:max_lag+2sequence_len) : collect(FT, 1:time_interval+2sequence_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "get_network (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "function get_network(alpha, architecture, initializer, input_size, hidden_size,output_size, tsteps)\n",
    "    if architecture == \"RNN_TANH\"\n",
    "        ∂rnncell = ∂RNNCell\n",
    "    elseif architecture == \"GRU\"\n",
    "        ∂rnncell = ∂GRUCell\n",
    "    else\n",
    "        ∂rnncell = ∂LSTMCell\n",
    "    end\n",
    "    \"\"\"\n",
    "    Ternary op -> reads as if initializer == \"limitcycle\" or architecture == \"LSTM\" use two argument function dispatch, else additionally pass initializer variable\n",
    "    \"\"\"\n",
    "    ∂rnn = initializer == \"limitcycle\" || architecture == \"LSTM\" ? ∂rnncell(input_size, hidden_size) : ∂rnncell(input_size,hidden_size,Flux.glorot_uniform)\n",
    "\n",
    "    node = RNNODE(∂rnn, (0.f0, tsteps[end]), saveat=tsteps, preprocess=x-> Float32.(onehot(x, ntoken=input_size-1)) )\n",
    "\n",
    "    function interpolate(x)\n",
    "        X = Zygote.ignore() do\n",
    "            permutedims(x) |> ConstantInterpolationFixedGrid\n",
    "        end\n",
    "    end\n",
    "    return Chain( interpolate, node, Array, x-> reshape(x, hidden_size, prod(size(x)[2:3])), Dense(hidden_size, output_size) )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = get_network(α, architecture, initializer, input_size, hidden_size,output_size, tsteps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "evaluate_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "function get_loss(dataset, max_lag, min_lag, time_interval)\n",
    "    \n",
    "    blank_token = 8\n",
    "    weight = ones(FT, output_size)\n",
    "    weight[blank_token] /= dataset == \"cm\" ? time_interval : mean([min_lag, max_lag]) \n",
    "    function logitcrossentropy(ŷ, y; dims=1, agg=mean)\n",
    "    agg(.-sum( (y .* logsoftmax(ŷ; dims=dims)).* weight; dims=dims))\n",
    "    end\n",
    "    return logitcrossentropy\n",
    "end\n",
    "nll = get_loss(dataset, max_lag, min_lag, time_interval)\n",
    "ℒ(ŷ::VecOrMat,y::VecOrMat) = nll(ŷ,y)\n",
    "ℒ(ŷ::VecOrMat,y::AbstractArray) = ℒ(ŷ, reshape(permutedims(y, (1,3,2)),9, prod(size(y)[2:3])))\n",
    "\n",
    "function evaluate_loss(x,y, 𝓁array)\n",
    "    ŷ = nn(x)\n",
    "    𝓁 = ℒ(ŷ,y)\n",
    "    push!(𝓁array, Zygote.dropgrad(deepcopy(𝓁[1])))  # make sure\n",
    "    return 𝓁\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "evaluate_set (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "classify(x) = argmax.(eachcol(x))\n",
    "\n",
    "function evaluate_set(model, data, 𝓁array, accarray, ℒ, set)\n",
    "    loss_set = Float32[]\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    @showprogress \"Evaluating $set\"  for (x,y) in data\n",
    "        # Only evaluate accuracy for n_batches\n",
    "        y = reshape(permutedims(y, (1,3,2)),9, prod(size(y)[2:3]))\n",
    "        ŷ = model(x)\n",
    "        𝓁 = ℒ(ŷ,y)\n",
    "        push!(loss_set, 𝓁[1])\n",
    "        target_class = classify(cpu(y))\n",
    "        predicted_class = classify(cpu(ŷ))\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    push!(accarray, (total_correct / total)[1] )\n",
    "    push!(𝓁array, mean(loss_set) )\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dict{Symbol,Array{Float32,1}} with 2 entries:\n",
       "  :loss     => Float32[]\n",
       "  :accuracy => Float32[]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "metrics[:valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0001"
      ],
      "text/latex": "0 . 0 0 0 1"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "opt = Flux.Optimiser(ClipValue(gradient_clipping), eval(optimizer)(η))\n",
    "ΔIT = 0\n",
    "min_ℒ = Inf\n",
    "Δthr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32mEvaluating valid100%|███████████████████████████████████| Time: 0:01:52\u001b[39m\n",
      "\u001b[32mEvaluating test100%|████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[32mEvaluating valid100%|███████████████████████████████████| Time: 0:02:12\u001b[39m\n",
      "\u001b[32mEvaluating test100%|████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[32mEvaluating valid100%|███████████████████████████████████| Time: 0:02:08\u001b[39m\n",
      "\u001b[32mEvaluating test100%|████████████████████████████████████| Time: 0:00:12\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:52:21\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@showprogress for i in 1:3\n",
    "        Flux.train!((x,y)->ℒ(nn(x),y), params(nn), train_loader, opt)\n",
    "        \n",
    "        if mapreduce(x -> isnan.(vec(x)), any ∘ vcat, params(nn))\n",
    "            @error \"NaN parameters detected. Breaking training loop.\"\n",
    "            break\n",
    "        end\n",
    "        for set in sets if set!= :train\n",
    "            evaluate_set(nn, eval_sets[set], metrics[set][:loss], metrics[set][:accuracy],ℒ,set)\n",
    "        end\n",
    "        end\n",
    "\n",
    "        if last(metrics[:valid][:loss]) < (1 - Δthr)min_ℒ\n",
    "            ΔIT=0\n",
    "            min_ℒ = last(metrics[:valid][:loss])\n",
    "            if !hpsearch\n",
    "                BSON.@save joinpath(save_dir, fname) params=cpu.(params(nn)) opt\n",
    "            end\n",
    "        elseif ΔIT >= patience && opt[2].eta > 1e-6\n",
    "            opt[2].eta*= factor\n",
    "        else\n",
    "            ΔIT+=1\n",
    "        end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}